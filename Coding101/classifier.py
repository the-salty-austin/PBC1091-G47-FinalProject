# import numpy
# from pandas import DataFrame
# from sklearn.feature_extraction.text import CountVectorizer
# from sklearn.naive_bayes import MultinomialNB
import random
from math import exp
import sqlite3
from selenium import webdriver
#import requests
#from bs4 import BeautifulSoup
import time

goods = "é“åœ°,è²¼å¿ƒ,å¤§æ¨,æ„‰å¿«,æ»¿æ„,å«©,å¥½åƒ,æ¨è–¦,é©šè±”,ç²¾ç·»,è¦ªåˆ‡,å„ª,cpå€¼é«˜,ç‰¹è‰²,æ–¹ä¾¿,æ°£æ°›ä½³,ä¸»å‹•,é©åˆ,æ¿ƒéƒ,ä¸éŒ¯,è®š,æ­£å®—,ç¾å‘³,ç´°å¿ƒ,çµ•é…,æ¸…çˆ½,å¾ˆæ£’,èˆ’æœ,è®šè®š,å†å»ä¸€æ¬¡,æ»¿è¶³,ğŸ‘,ğŸ˜‹,ğŸ˜"
goods = goods.split(',')
bads = "é€Ÿåº¦æ…¢,ä»½é‡å°‘,ä¸æ€éº¼æ¨£,å·®,æ“æ“ ,å‚»çœ¼,é›·,ç¡¬,æŸ´,é›£åƒ,å¤±æœ›,ä¸æ–°é®®,ä¸æœƒå†ä¾†,çˆ›,æ²¹,è†©,è…¥,è½å·®,æƒ¡åŠ£,ç”Ÿæ°£,ä¹…,ä¸é…,æµªè²»,è¶•äºº,å£æ°£,æ™®æ™®,ç™¼ç¥¨,æ‹‰è‚šå­,å›‚å¼µ,ä¹¾,åé«˜,åæ„Ÿ,æœå‹™å·®,åµ,äº‚"
bads = bads.split(',')

se = 'è¶Šå—èœ æ³°åœ‹èœ å°å°¼èœ é¦¬ä¾†è¥¿äºèœ å°åº¦èœ æ–°åŠ å¡èœ ç¾ä»£å°åº¦é¤å»³ è¶Šå¼æ²³ç²‰'
se = se.split(' ')
cn = 'ä¸Šæµ·æ–™ç† ä¸­èœ å®¢å®¶æ–™ç† å››å·æ–™ç† é¤ƒå­ å°ç£èœ ä¸­èœé¤¨ ä¸­åœ‹èœ ç²¥é¤å»³ ä¸­å¼éºµé£Ÿ æµ™èœ/æµ™æ±Ÿèœé¤¨ ä¸­å¼èŒ¶é¤¨ äº¬èœ/åŒ—äº¬èœé¤¨ æ¹˜èœé¤¨ æ¹¯ç¾¹'
cn = cn.split(' ')
brunch = ['æ—©åˆé¤']
street = ['è±†è…','å†·éºµåº—','éºµåº—','ç†Ÿé£Ÿåº—']
hk = ['ç²µå¼é»å¿ƒ','å»£æ±æ–™ç†','æ¸¯å¼å¿«é¤åº—']
jp = 'æ—¥å¼ä¸²ç‡’ ç‰›ä¸¼é¤å»³ å£½å¸ æµ·é®®ä¸¼é¤å»³ æ—¥æœ¬èœ æ­£å®—æ—¥å¼æ–™ç† æ—¥å¼ç‰›æ‰’é¤å»³ æ‹‰éºµ å¤©å©¦ç¾…ä¸¼é¤å»³ å’Œè“å­é¤å»³ æ—¥å¼ç‡’è‚‰ æ—¥å¼ç‚¸è±¬æ‰’é¤å»³ æ—¥å¼å’–å“© æ—¥æœ¬åœ°æ–¹æ–™ç†é¤å»³'
jp = jp.split(' ')
kr = ['éŸ“åœ‹èœ', 'éŸ“å¼çƒ¤è‚‰']
veg = ['åš´æ ¼ç´ é£Ÿæ–™ç†', 'ç´ é£Ÿæ–™ç†']
wes = 'å‚³çµ±ç¾å¼æ–™ç† ç¾ä»£æ­æ´²æ–™ç† ç¾ä»£è‹±åœ‹æ–™ç† æ³•åœ‹èœ æ¯”åˆ©æ™‚èœ åœŸè€³å…¶èœ æ­é™¸é¤å»³ å¢¨è¥¿å“¥èœ æ­å¼æ–™ç† å„ç¨®æ„å¤§åˆ©éºµ å¤å¨å¤·æ–™ç† ç¾å¼æ‰’æˆ¿ è¥¿ç­ç‰™é–‹èƒƒèœ é«˜ç´šæ³•å¼æ–™ç† æ‹‰ä¸ç¾æ´²æ–™ç† è¥¿ç­ç‰™èœ è¥¿éƒ¨æ–™ç† åœ°ä¸­æµ·èœ å¾·åœ‹èœ ç¾å¼é¤è»Šåº— æ„å¼è–„é¤… å—ç¾©å¤§åˆ©æ–™ç† æ³•å¼é¤å»³ è‘¡è„ç‰™èœ ç¾åœ‹èœ åœ°ä¸­æµ·èœ ç¾ä»£ç¾å¼æ–™ç† æ„å¤§åˆ©èœ ç¾ä»£æ³•å¼æ–™ç†ç‰›æ‰’ èåˆèœå¼é¤å»³'
wes = wes.split( )
hotel = ['é…’åº—', '5 æ˜Ÿç´šé£¯åº—', '4 æ˜Ÿç´šé£¯åº—', 'æº«æ³‰é…’åº—', '3 æ˜Ÿç´šé£¯åº—']
fast = ['é€Ÿé£Ÿ']
bar = ['å°é¤é¤¨ (Bistro)', 'å•¤é…’èŠ±åœ’', 'å±…é…’å±‹', 'é…’å§', 'é…’å§é›…åº§', 'åœ–æ›¸é¤¨']
sweet = ['å’–å•¡å»³', 'å’–å•¡åº—', 'ç”œå“åº—', 'é»å¿ƒ', 'å†°å“é£²æ–™åº—', 'è§€æ™¯å°', 'æ³•å¼ç³•é¤…åº—']
hotpot = ['å£½å–œç‡’é¤å»³', 'æ¶®æ¶®é‹', 'ç«é‹']

cuisine_lst = [se, cn, brunch, street, hk, jp, kr, veg, wes, hotel, fast, bar, sweet, hotpot]

driver = webdriver.Chrome()
driver.maximize_window()

def curve(x, k=0.12):
    '''
    Calculate individual score of every matched keyword
    '''
    # y=\frac{e^{ax}}{1+e^{ax}}-0.5
    score = exp(k*x)-1
    if score > 1:
        score = 1
    return score


def evaluate_review(score, review, goods, bads):
    '''
    Calculate the final score the entire comment
    new score = old score +- adjustments made by curve()
    '''
    for positive in goods:
        if positive in review:
            score += curve(len(positive))

    for negative in bads:
        if negative in review:
            score -= curve(len(negative))

    return score


def setupDB(cursor):
    cursor.executescript('''
    CREATE TABLE IF NOT EXISTS Data(
        id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,
        name TEXT UNIQUE,
        score REAL,
        cuisineID INTEGER,
        price INTEGER,
        geo TEXT
    );

    CREATE TABLE IF NOT EXISTS Cuisine(
        id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,
        cuisine TEXT UNIQUE
    );

    INSERT OR IGNORE INTO
        Cuisine(cuisine)
        VALUES
            ('æ±å—äºæ–™ç†'),('ä¸­å¼æ–™ç†'),('æ—©åˆé¤'),('å°åƒ'),('æ¸¯å¼æ–™ç†'),
            ('æ—¥å¼æ–™ç†'),('éŸ“å¼æ–™ç†'),('ç´ é£Ÿ'),('è¥¿å¼æ–™ç†'),('é£¯åº—é…’åº—'),
            ('é€Ÿé£Ÿ'),('é…’å§é¤é…’é¤¨'),('é£²æ–™ç”œå“ç³•é»'),('ç«é‹'),('å…¶ä»–'),('Bad Data')
        ;
    ''')


def write_toDB(connection, cursor, data):
    name, score, cuisine, price, geo = data[0], data[1], data[2], data[3], data[4]
    sqlstr = 'INSERT OR IGNORE INTO Data (name,score,cuisineID,price,geo) VALUES (?,?,?,?,?);'
    cursor.execute(sqlstr, (name, score, cuisine, price, geo))
    connection.commit()

def getGeo(url):
    #print('getting geo...', url)
    RETRY_LIM = 20
    driver.get(url)
    time.sleep(5)

    geo = ''
    for i in range(RETRY_LIM):
        try:
            # xpath = '//div[@jsan=\'7.ugiz4pqJLAG__primary-text,7.gm2-body-2\'][@class=\'ugiz4pqJLAG__primary-text gm2-body-2\']'
            xpath = '//button[@data-item-id=\'oloc\'][@data-tooltip=\'è¤‡è£½ plus code\']'
            geo = driver.find_element_by_xpath(xpath).text
            break
        except:
            time.sleep(0.5)
            continue

    #print(geo)
    
    return geo
    


conn = sqlite3.connect('Database\\scores.sqlite')
cur = conn.cursor()
setupDB(cur)

urls_csv = open(file='cleaned_urls.csv', mode='r', encoding='utf-8')

filecnt = 0
for urls_row in urls_csv:
    #print(urls_row)
    filecnt += 1

    if filecnt == 1 or urls_row.startswith('Center at'):
        continue

    else:
        urls_row = urls_row.split('"')
        url = urls_row[1]
        theRest = urls_row[2].split(',')
        #print(urls_row)
        try:
            price = int(theRest[2])
            name = theRest[3].strip()
            
            cui = theRest[1]
            for i in range(0,14):
                if cui in cuisine_lst[i]:
                    cuisine = i+1
                    break
                else:
                    cuisine = 15  # others
            
        except:
            name = 'N/A'
            price = -1
            cuisine = 16

        
        try:
            infile = open(file=f'.\\review_data\\cleaned\\cleaned_{filecnt-1}.csv', mode='r', encoding='utf-8')
            total = 0
            cnt = 0
            for line in infile:
                cnt += 1
                if cnt == 1:
                    org_avg = float(line.split(',')[-2])
                    continue

                line = line.split(',')
                r = line[0:-1]
                review = ''
                for part in r:
                    review += part

                if len(review) == 0:
                    continue

                rating = float(line[-1].strip())
                old_rating = rating

                new_rating = evaluate_review(old_rating, review, goods, bads)

                total += new_rating

                #print(review, old_rating, new_rating)

            new_avg = total/cnt
            new_avg = (0.75)*org_avg + (0.25)*new_avg

            #print(org_avg, new_avg)

            geo = getGeo(url)
            data = [name,new_avg,cuisine,price,geo]

            #print(data)
            write_toDB(conn, cur, data)
        except:
            geo = getGeo(url)
            data = [name,-1,cuisine,price,geo]
            write_toDB(conn, cur, data)


print(filecnt)